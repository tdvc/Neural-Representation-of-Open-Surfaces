{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf767b0",
   "metadata": {},
   "source": [
    "# Semi-Signed Distance Field for neural representation of open surfaces\n",
    "This Jupyter Notebook serves as a way to display the results from training a neural network to represent geometric shapes.\n",
    "\n",
    "You can visualize a 2D cross section of a particular shape and see how to access the latent vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b351a",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc635a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Geometric libraries\n",
    "import igl\n",
    "from pygel3d import hmesh, jupyter_display as jd\n",
    "jd.set_export_mode(True)\n",
    "\n",
    "# numpy libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from numpy.linalg import norm\n",
    "array = np.array\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Deep learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Libraries for environmetn\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fe1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sys.path.insert(1,os.path.join(os.getcwd(),\"..\",\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ccc3b",
   "metadata": {},
   "source": [
    "#### External functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0832c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.general import parse_cfg_file\n",
    "from utils.neural_network import data\n",
    "from utils.neural_network import Net   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b2c201",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(os.path.join(os.getcwd(),\"..\",\"..\",\".env\")), \\\n",
    "        \"Please create an .env file with appropriate directories and specification of configuration file\"\n",
    "load_dotenv()\n",
    "#--------------------------- \n",
    "# Environment\n",
    "#---------------------------\n",
    "\n",
    "# Data sets \n",
    "training_mesh_dir = os.path.join(os.getcwd(),os.getenv('mesh_train_dir'))\n",
    "test_mesh_dir = os.path.join(os.getcwd(),os.getenv('mesh_test_dir'))\n",
    "shape_completion_mesh_dir = os.path.join(os.getcwd(),os.getenv('mesh_shape_completion_dir'))\n",
    "\n",
    "# Model dir\n",
    "train_model_dir = os.path.join(os.getcwd(),os.getenv('ssdf_model_train_dir'))\n",
    "test_model_dir = os.path.join(os.getcwd(),os.getenv('ssdf_model_test_dir'))\n",
    "shape_completion_model_dir = os.path.join(os.getcwd(),os.getenv('ssdf_model_shape_completion_dir'))\n",
    "\n",
    "# Interpolation dir\n",
    "interpolation_dir = os.path.join(os.getcwd(),os.getenv('interpolation_dir'))\n",
    "shape_reconsruction_dir = os.path.join(os.getcwd(),\"shape_reconstruction\")\n",
    "\n",
    "# Configuration file\n",
    "cfg_file = os.getenv('cfg_file')\n",
    "assert os.path.exists(cfg_file), \\\n",
    "    \"Make sure you have the config file (.yaml) in the cfgs folder and set correct path in .env file\"\n",
    "cfg = parse_cfg_file(cfg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0826e",
   "metadata": {},
   "source": [
    "### Use GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f0893",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (cfg.use_GPU):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684ff34",
   "metadata": {},
   "source": [
    "## Load data and network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0701f9",
   "metadata": {},
   "source": [
    "#### Training data - Ground truth meshes and latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7fa29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_data = data(training_mesh_dir, train_model_dir, cfg.model_train.name, device)\n",
    "print(\"Number of training files:\", len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808f888",
   "metadata": {},
   "source": [
    "#### Test data - Ground truth meshes and latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data(test_mesh_dir, test_model_dir, cfg.model_test.name, device)\n",
    "print(\"Number of test files:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf56e3b",
   "metadata": {},
   "source": [
    "#### Shape completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_completion_data = data(shape_completion_mesh_dir, shape_completion_model_dir, \n",
    "                             cfg.model_shape_completion.name, device, test_mesh_dir)\n",
    "print(\"Number of training files:\", len(shape_completion_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc716c5",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0c5a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = Net(cfg.latent_vector.size + cfg.network.size_point, \n",
    "                cfg.network.num_hidden_units, cfg.network.multiple_output, device)\n",
    "\n",
    "checkpoint = torch.load(os.path.join(train_model_dir,cfg.model_train.name),map_location=device)\n",
    "net.load_state_dict(checkpoint['net_state_dict'])\n",
    "net = net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e182d3",
   "metadata": {},
   "source": [
    "## Cross Sectional result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18ae55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Training data\n",
    "'''\n",
    "#mesh, Faces, latent_vector = training_data[\"your_file.obj\"] # Replace .obj file with name of own file\n",
    "\n",
    "'''\n",
    "Test data\n",
    "'''\n",
    "mesh, Faces, latent_vector = test_data[\"Pants_138.obj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b8252",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos = mesh.positions()\n",
    "epsilon = 0.1\n",
    "bbox = hmesh.bbox(mesh)+epsilon*np.array([[-1,-1,-1],[1,1,1]])\n",
    "resolution = 500\n",
    "Y = np.linspace(bbox[0][1], bbox[1][1], resolution)\n",
    "Z = np.linspace(bbox[0][2], bbox[1][2], resolution)\n",
    "P = np.array([ np.array([0.0, Y[idx[0]], Z[idx[1]]]) for idx in np.ndindex((resolution,resolution))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37705632",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "UDF = abs(hmesh.MeshDistance(mesh).signed_distance(P))\n",
    "UDF = UDF.reshape((resolution,resolution))\n",
    "GWN = 2*np.array(igl.fast_winding_number_for_meshes(np.array(pos),np.array(Faces),np.array(P)))\\\n",
    "    -np.ones([1,resolution*resolution])\n",
    "GWN = GWN.reshape((resolution,resolution))\n",
    "SSDF = np.multiply(GWN, UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1771ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net_input = torch.cat((latent_vector.repeat(len(P),1).detach(),torch.from_numpy(P).float().to(device)),1)\n",
    "\n",
    "net_output = net(net_input)\n",
    "net_output_np = net_output.detach().numpy()\n",
    "\n",
    "net_UDF = net_output_np[:,0]\n",
    "net_UDF = net_UDF.reshape((resolution,resolution))\n",
    "\n",
    "net_SSDF = net_output_np[:,1]\n",
    "net_SSDF = net_SSDF.reshape((resolution,resolution))\n",
    "\n",
    "net_GWN = np.true_divide(net_SSDF,net_UDF+1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb401fc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(nrows=3, ncols=2, figsize=(20, 20), constrained_layout=True)\n",
    "\n",
    "ax = axarr[0][0]\n",
    "levels = [0]\n",
    "cs = ax.contour(SSDF, levels,colors=['red'])\n",
    "im3 = ax.imshow(SSDF, interpolation='bilinear', origin='lower')\n",
    "ax.set_xlabel('y',fontsize=25)\n",
    "ax.set_ylabel('z',fontsize=25)\n",
    "f.colorbar(im3,ax = axarr[0][0])\n",
    "ax.set_title(\"Ground Truth SSDF, x = 0.0\", size=30)\n",
    "\n",
    "ax = axarr[0][1]\n",
    "levels = [0]\n",
    "cs = ax.contour(net_SSDF, levels,colors=['red'] )\n",
    "im3 = ax.imshow(net_SSDF, interpolation='bilinear', origin='lower')\n",
    "ax.set_xlabel('y',fontsize=25)\n",
    "ax.set_ylabel('z',fontsize=25)\n",
    "f.colorbar(im3,ax = axarr[0][1])\n",
    "ax.set_title(\"Network SSDF, x = 0.0\", size=30)\n",
    "\n",
    "ax = axarr[1][0]\n",
    "levels = [0]\n",
    "cs = ax.contour(UDF, levels)\n",
    "im3 = ax.imshow(UDF, interpolation='bilinear', origin='lower')\n",
    "ax.set_xlabel('y',fontsize=25)\n",
    "ax.set_ylabel('z',fontsize=25)\n",
    "f.colorbar(im3,ax = axarr[1][0])\n",
    "ax.set_title(\"Ground Truth UDF, x = 0.0\", size=30)\n",
    "\n",
    "ax = axarr[1][1]\n",
    "levels = [0]\n",
    "cs = ax.contour(net_UDF, levels)\n",
    "im3 = ax.imshow(net_UDF, interpolation='bilinear', origin='lower')\n",
    "ax.set_xlabel('y',fontsize=25)\n",
    "ax.set_ylabel('z',fontsize=25)\n",
    "f.colorbar(im3,ax = axarr[1][1])\n",
    "ax.set_title(\"Network UDF, x = 0.0\", size=30)\n",
    "\n",
    "ax = axarr[2][0]\n",
    "levels = [-75, -70, -65, -60, -55, -50, -45, -40, -35, -30, -25, -20, -15, -10, -5, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "cs = ax.contour(GWN, levels)\n",
    "im3 = ax.imshow(GWN, interpolation='bilinear', origin='lower')\n",
    "ax.set_xlabel('y',fontsize=25)\n",
    "ax.set_ylabel('z',fontsize=25)\n",
    "f.colorbar(im3,ax = axarr[2][0])\n",
    "ax.set_title(\"Ground Truth GWN, x = 0.0\", size=30)\n",
    "\n",
    "ax = axarr[2][1]\n",
    "levels = [0]\n",
    "cs = ax.contour(net_GWN, levels,colors=['red'])\n",
    "im3 = ax.imshow(net_GWN, interpolation='bilinear', origin='lower')\n",
    "ax.set_xlabel('y',fontsize=25)\n",
    "ax.set_ylabel('z',fontsize=25)\n",
    "f.colorbar(im3,ax = axarr[2][1])\n",
    "ax.set_title(\"Network GWN, x = 0.0\", size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d050aa5",
   "metadata": {},
   "source": [
    "### Latent Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.latent_vectors.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eca647",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.latent_vectors.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_completion_data.latent_vectors.detach().cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssdf",
   "language": "python",
   "name": "ssdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
